{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ERAU REU 2021 NNSS PROJECT 1.0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPnCjsLW+X+nzQqN6Ask1Cr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LordofD-MBrown/2021_ERAU_REU_NNSS_Variable_Stride_Algorithm_Analysis/blob/main/ERAU_REU_2021_NNSS_PROJECT_1_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5B7Dgn_b5uL"
      },
      "source": [
        "#ERAU REU 2021 NNSS PROJECT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOYpn9qxclk2"
      },
      "source": [
        "Programmed By: Matthew Brown\n",
        "\n",
        "Programmed In: Python using Google Colab\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNBPmxoJoQZm",
        "outputId": "41e83cf0-daed-4fc6-98d9-8486131e093e"
      },
      "source": [
        "#Connecting Program to Google Drive\n",
        "#=====================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "#====================================================="
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRvuHk2QeTQC"
      },
      "source": [
        "#Imports\n",
        "#===============================================================================\n",
        "import cv2\n",
        "import keras\n",
        "import matplotlib\n",
        "import pickle\n",
        "import os\n",
        "import random\n",
        "import sklearn\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import activations\n",
        "from keras import backend as K\n",
        "from PIL import Image\n",
        "from sklearn import metrics\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Flatten, Layer\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "#==============================================================================="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKwflqJ9QdLY"
      },
      "source": [
        "The following code is gathering the data and turning it into an array that the neural network can read. The image sizes have been preset to be 600 x 600. There are 200 entries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOi8ZuPPIhAj"
      },
      "source": [
        "#Compiling Data to Test With\n",
        "#===============================================================================\n",
        "Data_Location = '/gdrive/My Drive/ERAU_REU_SUMMER_2021/ERAU_retinopathy_data_rotated'\n",
        "Classifications = [\"Class 1\", \"Class 4\"]\n",
        "\n",
        "training_data = []\n",
        "\n",
        "def initialize_training_data():\n",
        "  for classification in Classifications:\n",
        "    path = os.path.join(Data_Location, classification)\n",
        "    classification_num = Classifications.index(classification) # 0 = Class 1, 1 = Class 4\n",
        "    for img in os.listdir(path):\n",
        "      img_array = cv2.imread(os.path.join(path, img))\n",
        "      training_data.append([img_array, classification_num])\n",
        "initialize_training_data()\n",
        "random.shuffle(training_data) #Makes sure there is no order to the data set\n",
        "\n",
        "Image_Array = []\n",
        "Label_Array = []\n",
        "\n",
        "for features, label in training_data:\n",
        "  Image_Array.append(features)\n",
        "  Label_Array.append(label)\n",
        "\n",
        "Image_Array = np.array(Image_Array).reshape(-1,600,600,3) #Note the last value is 3 as it is in RGB\n",
        "#==============================================================================="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Skt66a3T3Xwt"
      },
      "source": [
        "pickle_out = open(\"Image_Array_0.pickle\", \"wb\")\n",
        "pickle.dump(Image_Array, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"Label_Array_0.pickle\", \"wb\")\n",
        "pickle.dump(Label_Array, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bYaju0kffG3"
      },
      "source": [
        "# Max Pool Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUMXogOWfurA"
      },
      "source": [
        "#Max Pool Pre-Processing\n",
        "#===============================================================================\n",
        "pickle_in = open(\"Image_Array_0.pickle\", \"rb\")\n",
        "Image_Array = pickle.load(pickle_in)\n",
        "pickle_in = open(\"Label_Array_0.pickle\", \"rb\")\n",
        "Label_Array = pickle.load(pickle_in)\n",
        "#Scaling the Variables\n",
        "#===================================\n",
        "Image_Array = np.array(Image_Array / 255.0)\n",
        "Label_Array = np.array(Label_Array)\n",
        "#===================================\n",
        "\n",
        "#Indexing\n",
        "#==========================================\n",
        "image_number = 0\n",
        "#==========================================\n",
        "\n",
        "#Setting Parameters\n",
        "#==========================================\n",
        "filter_x = 2\n",
        "filter_y = 2\n",
        "filter_z = 3                                                                    #filter size 2x2x3\n",
        "input_shape = (Image_Array.shape)\n",
        "nx = input_shape[1]\n",
        "ny = input_shape[2]\n",
        "nz = input_shape[3]\n",
        "\n",
        "output_dim = (int(input_shape[1] / filter_x), int(input_shape[2] / filter_y), filter_z)\n",
        "print(output_dim)\n",
        "post_vs_image_array = np.zeros((Image_Array.shape[0], ) + output_dim)                 \n",
        "#==========================================\n",
        "while image_number < Image_Array.shape[0]:\n",
        "  print(image_number)  \n",
        "  input_image = Image_Array[image_number]                                       #Successful\n",
        "  post_vs_image = np.zeros(output_dim)                                          #Successful sets to (332,240,3)      \n",
        "\n",
        "  oldrow = 0\n",
        "  oldcol = 0\n",
        "\n",
        "  new_col_idx = 0\n",
        "  new_row_idx = 0\n",
        "\n",
        "  while (oldrow < nx - 1 and new_row_idx < post_vs_image.shape[0]):\n",
        "\n",
        "    while (oldcol < ny - 1 and new_col_idx < post_vs_image.shape[1]):\n",
        "\n",
        "      temp_r = tf.keras.backend.get_value(input_image[oldrow:oldrow + filter_x,oldcol:oldcol + filter_y,0])\n",
        "      temp_g = tf.keras.backend.get_value(input_image[oldrow:oldrow + filter_x,oldcol:oldcol + filter_y,1])\n",
        "      temp_b = tf.keras.backend.get_value(input_image[oldrow:oldrow + filter_x,oldcol:oldcol + filter_y,2])\n",
        "\n",
        "      max_r = np.max(temp_r)\n",
        "      max_g = np.max(temp_g)\n",
        "      max_b = np.max(temp_b)\n",
        "\n",
        "      post_vs_image[new_row_idx, new_col_idx, 0] = max_r\n",
        "      post_vs_image[new_row_idx, new_col_idx, 1] = max_g\n",
        "      post_vs_image[new_row_idx, new_col_idx, 2] = max_b\n",
        "\n",
        "      #=========================================================================\n",
        "      oldcol += filter_y\n",
        "      new_col_idx += 1\n",
        "    oldcol = 0\n",
        "    new_col_idx = 0\n",
        "    oldrow += filter_x\n",
        "    new_row_idx += 1\n",
        "    #===========================================================================\n",
        "  post_vs_image_array[image_number] = post_vs_image\n",
        "  image_number += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyV3tBMsH11N"
      },
      "source": [
        "#Saving Pickles\n",
        "#===============================================================================\n",
        "#tf.keras.preprocessing.image.array_to_img(Image_Array[0], scale = True)\n",
        "tf.keras.preprocessing.image.array_to_img(post_vs_image_array[1], scale = True)\n",
        "print()\n",
        "pickle_out = open(\"max_pool_image_array.pickle\", \"wb\")\n",
        "pickle.dump(post_vs_image_array, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"label_array_1.pickle\", \"wb\")\n",
        "pickle.dump(Label_Array, pickle_out)\n",
        "pickle_out.close()\n",
        "#==============================================================================="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wfZ94DJVsms"
      },
      "source": [
        "# Avg Pool Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzhPIQnsV4SB"
      },
      "source": [
        "#Avg Pool Pre-Processing\n",
        "#===============================================================================\n",
        "pickle_in = open(\"Image_Array_0.pickle\", \"rb\")\n",
        "Image_Array = pickle.load(pickle_in)\n",
        "pickle_in = open(\"Label_Array_0.pickle\", \"rb\")\n",
        "Label_Array = pickle.load(pickle_in)\n",
        "#Scaling the Variables\n",
        "#===================================\n",
        "Image_Array = np.array(Image_Array / 255.0)\n",
        "Label_Array = np.array(Label_Array)\n",
        "#===================================\n",
        "\n",
        "#Indexing\n",
        "#==========================================\n",
        "image_number = 0\n",
        "#==========================================\n",
        "\n",
        "#Setting Parameters\n",
        "#==========================================\n",
        "filter_x = 2\n",
        "filter_y = 2\n",
        "filter_z = 3                                                                    #filter size 2x2x3\n",
        "input_shape = (Image_Array.shape)\n",
        "nx = input_shape[1]\n",
        "ny = input_shape[2]\n",
        "nz = input_shape[3] \n",
        "\n",
        "output_dim = (int(input_shape[1] / filter_x), int(input_shape[2] / filter_y), filter_z)\n",
        "print(output_dim)\n",
        "post_vs_image_array = np.zeros((Image_Array.shape[0], ) + output_dim)                 \n",
        "#==========================================\n",
        "while image_number < Image_Array.shape[0]:\n",
        "  print(image_number)  \n",
        "  input_image = Image_Array[image_number]                                       #Successful\n",
        "  post_vs_image = np.zeros(output_dim)                                          #Successful sets to (332,240,3)      \n",
        "\n",
        "  oldrow = 0\n",
        "  oldcol = 0\n",
        "\n",
        "  new_col_idx = 0\n",
        "  new_row_idx = 0\n",
        "\n",
        "  while (oldrow < nx - 1 and new_row_idx < post_vs_image.shape[0]):\n",
        "\n",
        "    while (oldcol < ny - 1 and new_col_idx < post_vs_image.shape[1]):\n",
        "\n",
        "      temp_r = tf.keras.backend.get_value(input_image[oldrow:oldrow + filter_x,oldcol:oldcol + filter_y,0])\n",
        "      temp_g = tf.keras.backend.get_value(input_image[oldrow:oldrow + filter_x,oldcol:oldcol + filter_y,1])\n",
        "      temp_b = tf.keras.backend.get_value(input_image[oldrow:oldrow + filter_x,oldcol:oldcol + filter_y,2])\n",
        "\n",
        "      avg_r = np.average(temp_r)\n",
        "      avg_g = np.average(temp_g)\n",
        "      avg_b = np.average(temp_b)\n",
        "\n",
        "      post_vs_image[new_row_idx, new_col_idx, 0] = avg_r\n",
        "      post_vs_image[new_row_idx, new_col_idx, 1] = avg_g\n",
        "      post_vs_image[new_row_idx, new_col_idx, 2] = avg_b\n",
        "\n",
        "      #=========================================================================\n",
        "      oldcol += filter_y\n",
        "      new_col_idx += 1\n",
        "    oldcol = 0\n",
        "    new_col_idx = 0\n",
        "    oldrow += filter_x\n",
        "    new_row_idx += 1\n",
        "    #===========================================================================\n",
        "  post_vs_image_array[image_number] = post_vs_image\n",
        "  image_number += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJPq-fJ_WaCK",
        "outputId": "8152ea7c-e0a7-4c6d-a058-87e4a801caea"
      },
      "source": [
        "#tf.keras.preprocessing.image.array_to_img(Image_Array[0], scale = True)\n",
        "tf.keras.preprocessing.image.array_to_img(post_vs_image_array[1], scale = True)\n",
        "print(Label_Array[1])\n",
        "#pickle_out = open(\"average_pool_image.pickle\", \"wb\")\n",
        "#pickle.dump(post_vs_image_array, pickle_out)\n",
        "#pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGX4zouWp3r5"
      },
      "source": [
        "# Variable Stide Pre-Processing#\n",
        "This code a pre-processing version of variable stride that can be implemented to the images before they are entered in the CNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POn-Twn4p3AD"
      },
      "source": [
        "#Caluculating Variable Stride Out Shape\n",
        "#===============================================================================\n",
        "def CalcVSOutShape(input_shape,              #(q,x,y,z)\n",
        "                   step_v = [4, 1, 4],       #Vertical Step\n",
        "                   step_h = [4, 1, 4],          #Horizontal Step\n",
        "                   frac_v = [1/3, 1/3, 1/3], \n",
        "                   frac_h = [1/3, 1/3, 1/3]):\n",
        "  #print('Input Shape:', input_shape)\n",
        "  (q, nx, ny, nz) = input_shape                 #Sets the nx, ny, nz = input x,y,z\n",
        "  #print(nx)                                 #600\n",
        "  #print(ny)                                 #600\n",
        "  #print(nz)                                 #3\n",
        "  cum_frac_v = np.cumsum(frac_v)             #Return the cumulative sum of the elements along a given axis.\n",
        "  cum_frac_h = np.cumsum(frac_h)\n",
        "  #print(cum_fraction_v)                     #[0.33333333 0.66666667 1.]\n",
        "  #print(cum_fraction_h)                     #[0.25 1.]\n",
        "  frac_bounds_v = cum_frac_v * (nx-0) - 1\n",
        "  frac_bounds_h = cum_frac_h * (ny-0) - 1\n",
        "  #print(frac_bounds_v)                      #[199. 399. 599.]\n",
        "  #print(frac_bounds_h)                      #[149. 599.]\n",
        "\n",
        "  out_h = 0\n",
        "  out_v = 0\n",
        "  idx_low = 0\n",
        "\n",
        "  for frac_idx in range(len(frac_h)):\n",
        "    idx_span = min(frac_bounds_h[frac_idx], ny - 3) - idx_low                   \n",
        "    divisor_h, remander_h = divmod(idx_span, step_h[frac_idx])\n",
        "    out_h += int(divisor_h) + 1\n",
        "    idx_low += (int(divisor_h) + 1) * step_h[frac_idx]\n",
        "\n",
        "  idx_low = 0\n",
        "\n",
        "  for frac_idx in range(len(frac_v)):\n",
        "    idx_span = min(frac_bounds_v[frac_idx], nx - 3) - idx_low  \n",
        "    divisor_v, remainder_v = divmod(idx_span, step_v[frac_idx])\n",
        "    out_v += int(divisor_v) + 1\n",
        "    idx_low += (int(divisor_v) + 1) * step_v[frac_idx]\n",
        "\n",
        "  #print(out_v)             #332\n",
        "  #print(out_h)             #240 \n",
        "  #print(nz)                #3\n",
        "  return (out_v, out_h, nz)\n",
        "#===============================================================================\n",
        "\n",
        "#Variable Stride\n",
        "#===============================================================================\n",
        "pickle_in = open(\"Image_Array_0.pickle\", \"rb\")\n",
        "Image_Array = pickle.load(pickle_in)\n",
        "pickle_in = open(\"Label_Array_0.pickle\", \"rb\")\n",
        "Label_Array = pickle.load(pickle_in)\n",
        "#Scaling the Variables\n",
        "#===================================\n",
        "Image_Array = np.array(Image_Array / 255.0)\n",
        "Label_Array = np.array(Label_Array)\n",
        "#===================================\n",
        "\n",
        "#Indexing\n",
        "#==========================================\n",
        "image_number = 0\n",
        "#==========================================\n",
        "\n",
        "#Setting Parameters\n",
        "#==========================================\n",
        "k1 = np.array([[1, 2, 1],\n",
        "               [2, 4, 2],\n",
        "               [1, 2, 1]])\n",
        "step_v = [2, 3, 1, 3, 2]      #Vertical Step\n",
        "step_h = [3,2]       #Horizontal Step\n",
        "frac_v = [1/5, 1/5, 1/5, 1/5, 1/5]\n",
        "frac_h = [1/5, 4/5]\n",
        "\n",
        "input_shape = (Image_Array.shape)\n",
        "nx = input_shape[1]\n",
        "ny = input_shape[2]\n",
        "nz = input_shape[3] \n",
        "\n",
        "output_dim = CalcVSOutShape(input_shape, step_h = step_h, step_v = step_v, frac_v = frac_v, frac_h = frac_h)\n",
        "print(output_dim)\n",
        "kernel = np.repeat(k1[:,:,np.newaxis], nz, axis = 2)\n",
        "post_vs_image_array = np.zeros((Image_Array.shape[0], ) + output_dim)                 \n",
        "#==========================================\n",
        "while image_number < Image_Array.shape[0]:\n",
        "  print(image_number)\n",
        "  input_image = Image_Array[image_number]                                       #Successful\n",
        "  post_vs_image = np.zeros(output_dim)                                          #Successful sets to (332,240,3)      \n",
        "\n",
        "  mystep_v = 0\n",
        "  mystep_h = 0\n",
        "  myfrac_v = 0\n",
        "  myfrac_h = 0\n",
        "\n",
        "  oldrow = 0\n",
        "  oldcol = 0\n",
        "\n",
        "  new_col_idx = 0\n",
        "  new_row_idx = 0\n",
        "\n",
        "  while (oldrow < nx - 2 and new_row_idx < post_vs_image.shape[0]):  \n",
        "    while (oldcol < ny - 2 and new_col_idx < post_vs_image.shape[1]):                    \n",
        "      temp = tf.keras.backend.get_value(input_image[oldrow:oldrow + 3, oldcol:oldcol + 3, :])\n",
        "      temp = (temp * kernel)                                                           \n",
        "      post_vs_image[new_row_idx, new_col_idx, :] = np.sum(np.sum(temp,axis = 0), axis = 0)\n",
        "      #=========================================================================\n",
        "      if oldcol > (np.sum(frac_h[0:myfrac_h + 1]) * nx - 1):\n",
        "        mystep_h += 1\n",
        "        myfrac_h += 1\n",
        "      oldcol += step_h[mystep_h]\n",
        "      new_col_idx += 1\n",
        "    if oldrow > (np.sum(frac_v[0:myfrac_v + 1]) * ny - 1):\n",
        "      mystep_v += 1\n",
        "      myfrac_v += 1\n",
        "    oldcol = 0\n",
        "    mystep_h = 0\n",
        "    myfrac_h = 0\n",
        "    oldrow += step_v[mystep_v]\n",
        "    new_col_idx = 0\n",
        "    new_row_idx += 1\n",
        "    #===========================================================================\n",
        "  post_vs_image_array[image_number] = post_vs_image\n",
        "  image_number += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIbHTrs9qjhv"
      },
      "source": [
        "#tf.keras.preprocessing.image.array_to_img(Image_Array[0], scale = True)\n",
        "pickle_in = open(\"variable_stride_custom_image_array.pickle\", \"rb\")\n",
        "x = pickle.load(pickle_in)\n",
        "tf.keras.preprocessing.image.array_to_img(x[0], scale = True)\n",
        "#pickle_out = open(\"variable_stride_custom_image_array.pickle\", \"wb\")\n",
        "#pickle.dump(post_vs_image_array, pickle_out)\n",
        "#pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-3jmj8lTtSO"
      },
      "source": [
        "Saving the Image Array:\n",
        "\n",
        "After running the code on a new stride method, you must save the following pickle file to you computer then reupload it next session to keep data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPiT8nBHbf_T"
      },
      "source": [
        "pickle_out = open(\"Image_Array.pickle\", \"wb\")\n",
        "pickle.dump(Image_Array, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"label_array.pickle\", \"wb\")\n",
        "pickle.dump(Label_Array, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTQOc1sLfQbe"
      },
      "source": [
        "# Reset the TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSlwU2OplsGz"
      },
      "source": [
        "#Refresh Logs\n",
        "#===============================================================================\n",
        "%rm -rf logs #Reset Logs\n",
        "#==============================================================================="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgakZcNBVFlt"
      },
      "source": [
        "# **The Convolutional Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgiqydt-H8BW"
      },
      "source": [
        "#The Convolutional Neural Network\n",
        "#===============================================================================\n",
        "pickle_in = open(\"Image_Array_0.pickle\", \"rb\")\n",
        "x = pickle.load(pickle_in)\n",
        "pickle_in = open(\"Label_Array_0.pickle\", \"rb\")\n",
        "y = pickle.load(pickle_in)\n",
        "#============================logs of progress===================================\n",
        "logdir = os.path.join(\"logs\", \"7_64_64_64_32_16_1_Dropout_.7\") #Edit Name of Logs\n",
        "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
        "#===============================================================================\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#Layer - Convolutional Layer\n",
        "#===================================\n",
        "model.add(Conv2D(64, (5,5), activation = 'relu', input_shape = (300, 300, 3)))  #Check\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#===================================\n",
        "\n",
        "#Layer - Convolutional Layer\n",
        "#===================================\n",
        "model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
        "model.add(Dropout(.2))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#===================================\n",
        "\n",
        "#Layer - Convolutional Layer\n",
        "#===================================\n",
        "model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
        "model.add(Dropout(.2))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#===================================\n",
        "\n",
        "#Layer - Convolutional Layer\n",
        "#===================================\n",
        "model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
        "model.add(Dropout(.2))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#===================================\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "#Layer - Dense\n",
        "#===================================\n",
        "model.add(Dense(32, activation = 'relu'))\n",
        "#===================================\n",
        "\n",
        "#Layer - Dense\n",
        "#===================================\n",
        "model.add(Dense(16, activation = 'relu'))\n",
        "#===================================\n",
        "\n",
        "#Layer - Output\n",
        "#===================================\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "#===================================\n",
        "\n",
        "model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = ['accuracy'])\n",
        "model.fit(x, y, batch_size = 10, epochs = 100, validation_split=.15, callbacks=[tensorboard_callback], shuffle = True)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#Load Tensor Board\n",
        "#===============================================================================\n",
        "#%reload_ext tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs\n",
        "#==============================================================================="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpF8j-WXDJK7"
      },
      "source": [
        "# Testing Different Stuctures of Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZPdQrRfMPnQ"
      },
      "source": [
        "pickle_in = open(\"average_pool_image.pickle\", \"rb\")\n",
        "x = pickle.load(pickle_in)\n",
        "pickle_in = open(\"Label_Array_0.pickle\", \"rb\")\n",
        "y = pickle.load(pickle_in)\n",
        "tf.keras.preprocessing.image.array_to_img(x[1], scale = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koWEexW0Dpm9"
      },
      "source": [
        "Classifications = [\"Class 1\", \"Class 4\"]\n",
        "\n",
        "dense_layers = [4]                                                              #Adjust dense layers                                                   \n",
        "layer_sizes = [64]                                                              #Adjust number of Nodes\n",
        "conv_layers = [5]                                                               #Adjust conv layers\n",
        "drop_out_rates = [.05]                                                           #Adjust drop out rate\n",
        "valid_seperation = .2\n",
        "\n",
        "total_runs = 8\n",
        "current_run = 0\n",
        "dim = (40, 319, 279, 3) #266,332                                                  #Adjust input dimensions Avg. Max = 40,300,300,3  Custom = 40,319,279,3  Center = 40,300,300,3 Right = 40,332,266,3\n",
        "\n",
        "pickle_in = open(\"variable_stride_custom_image_array.pickle\", \"rb\")\n",
        "x = pickle.load(pickle_in)\n",
        "pickle_in = open(\"Label_Array_0.pickle\", \"rb\")\n",
        "y = pickle.load(pickle_in)\n",
        "\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "test_data_1 = int(200 - (200 * valid_seperation))\n",
        "test_data_2 = int(200 - (200 * valid_seperation))\n",
        "\n",
        "i = 0\n",
        "\n",
        "test_data_image = np.zeros(dim)\n",
        "test_data_label = np.zeros(40)\n",
        "\n",
        "for test_data_1 in range(test_data_2, 200):\n",
        "  test_data_image[i] = x[test_data_1]\n",
        "  test_data_label[i] = y[test_data_1]\n",
        "  i += 1\n",
        "\n",
        "for current_run in range(0, total_runs):\n",
        "  for dense_layer in dense_layers:\n",
        "    for layer_size in layer_sizes:\n",
        "      for conv_layer in conv_layers:\n",
        "        for drop_out in drop_out_rates:\n",
        "          NAME = \"{}-conv-{}-nodes-{}-dense-{}-dropout-{}-run-{}\".format(conv_layer, layer_size, dense_layer,drop_out, (current_run + 1), int(time.time()))\n",
        "\n",
        "          print(NAME)\n",
        "          model = Sequential()\n",
        "\n",
        "          model.add(Conv2D(layer_size, (3,3), input_shape = (319, 279, 3)))      #Adjust input dimensions Avg. Max = 300,300,3  Custom = 319,279,3  Center = 300,300,3 Right = 332,266,3\n",
        "          model.add(Activation(\"relu\"))\n",
        "          model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "          model.add(Dropout(drop_out))\n",
        "\n",
        "          for l in range(conv_layer - 1):\n",
        "            model.add(Conv2D(layer_size, (3, 3)))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "            model.add(Dropout(drop_out))\n",
        "      \n",
        "          model.add(Flatten())\n",
        "\n",
        "          for l in range(dense_layer):\n",
        "            model.add(Dense(layer_size))\n",
        "            model.add(Activation('relu'))\n",
        "\n",
        "          model.add(Dense(1))\n",
        "          model.add(Activation('sigmoid'))\n",
        "\n",
        "          #============================logs of progress===================================\n",
        "          logdir = os.path.join(\"logs\", NAME) #Edit Name of Logs\n",
        "          tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
        "          stop = tf.keras.callbacks.EarlyStopping(monitor = 'accuracy', patience = 10)\n",
        "          #===============================================================================\n",
        "\n",
        "          model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = ['accuracy'])\n",
        "          model.fit(x, y, batch_size = 10, epochs = 150, validation_split = valid_seperation, callbacks = [tensorboard_callback], shuffle = True)\n",
        "\n",
        "          model.summary()\n",
        "\n",
        "          label_pred_keras = model.predict(test_data_image, batch_size = 1)\n",
        "          fpr_keras, tpr_keras, thresholds_keras = sklearn.metrics.roc_curve(test_data_label, label_pred_keras)\n",
        "          auc = sklearn.metrics.roc_auc_score(test_data_label, label_pred_keras)\n",
        "\n",
        "          plt.figure(1)\n",
        "          plt.plot([0, 1], [0, 1], 'k--')\n",
        "          plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc))\n",
        "          plt.xlabel('False positive rate')\n",
        "          plt.ylabel('True positive rate')\n",
        "          plt.title('ROC curve')\n",
        "          plt.legend(loc='best')\n",
        "          plt.show()\n",
        "\n",
        "          for n in range(np.max(np.size(label_pred_keras))):\n",
        "            if label_pred_keras[n,0] < .5:\n",
        "              label_pred_keras[n,0] = 0\n",
        "            if label_pred_keras[n,0] >= 0.5:\n",
        "              label_pred_keras[n,0] = 1\n",
        "            \n",
        "          print('Classification Report')\n",
        "\n",
        "          print(sklearn.metrics.classification_report(test_data_label,label_pred_keras,target_names = Classifications))\n",
        "\n",
        "#Load Tensor Board\n",
        "#===============================================================================\n",
        "#%reload_ext tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs\n",
        "#==============================================================================="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKwdSKbjKrkV"
      },
      "source": [
        "#Load Tensor Board\n",
        "#===============================================================================\n",
        "#%reload_ext tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs\n",
        "#==============================================================================="
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}